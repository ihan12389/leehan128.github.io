# Dynamic Programming

> 입력 크기가 작은 부분문제들을 모두 해결한 후에 그 해들을 이용하여 보다 큰 크기의 부분문제들을 해결하여, 최종적으로 원래 주어진 입력의 문제를 해결
>
> 큰 문제를 작은 문제로 나누어 풀기 때문에 분할 정복 알고리즘과 개념이 비슷하다

### 1. 분할 정복 알고리즘과의 차이는?

<img src="https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQG8SuSMTTnM_CtlymIRQ0N17qx504-AK1l2Sk3E4Prme9xcsS_&amp;usqp=CAU"  />

두 알고리즘 간의 결정적인 차이점은 `작은 문제가 중복이 일어나는지 안일어나는지`입니다. 분할 문제는 단지 문제를 분할할 뿐이지만 동적 프로그래밍은 작은 부분문제들이 반복되는 것을 이용해 문제를 풀어나가죠.

위의 그래프를 봅시다. 분할정복 알고리즘은 A가 B와 C로 또 그것들이 D E F G로 분해되는데, D와 E의 해를 취합하여 B의 해를 구하고 F와 G의 해를 구하여 C의 해를 구합니다. 마지막으로 B와 C의 해를 취합하여 A의 해를 얻는데 이 과정을 분할정복 알고리즘이라고 하죠.

반면에 동적 프로그래밍은 최소 단위인 D E F G의 해를 각각 구한 후에, D E F의 해를 이용하여 B의 해를 구하고, E F G의 해를 이용하여 C의 해를 구합니다. 네, 분할 정복에서는 B와 C의 해를 구하는데 부분문제가 **중복**될 일이 없었습니다. 그러나 동적 프로그래밍에서는 B와 C의 해를 구하는데 E와 F가 모두 중복되어 사용되었습니다.

동적 프로그래밍에는 부분문제들 사이에 의존적 관계가 존재합니다. 예를 들면 D E F의 해가 B를 해결하는데 사용되는 것처럼요. 이러한 관계는 문제 또는 입력에 따라 다르고 대부분의 경우 또렷이 보이지 않아서 `함축적인 순서`라고 합니다.

### 2. 동적 계획 알고리즘의 특징

동적 계획 알고리즘은 모든 작은 문제들을 한번만 풀이합니다.

그리고 구한 부분문제의 정답을 어딘가에 메모해 놓습니다.

다시 그보다 큰 문제를 풀어나갈 때 똑같은 부분 문제가 필요하면 메모한 내용을 이용합니다.

동적 계획 알고리즘이 어울리는 문제의 조건은 다음과 같습니다.

* 작은 문제가 반복이 일어나는 경우
* 같은 문제는 구할 때마다 정답이 같을 경우

자, 다음 문제들을 통해 직접 확인해봅시다.

### 3. 모든 쌍 최단 경로 찾기

그리디 알고리즘에서 다익스트라 알고리즘을 사용해 각 점 사이의 최단 경로를 찾을 수 있었습니다. 이 다익스트라 알고리즘을 사용해 모든 쌍의 최단 경로를 찾는 것도 가능합니다. 그러나 그보다 쉽게 모든 쌍의 최단 경로를 찾기 위한 `플로이드-워셜`알고리즘이 있습니다.

먼저 플로이드-워셜 알고리즘의 스펙을 보면 O(n<sup>3</sup>)으로 다익스트라 알고리즘을 적용했을 때와 차이는 없지만 구현이 훨씬 간편하다는 점에서 이점이 있습니다.

그럼 동적 프로그래밍인 플로이드-워셜 알고리즘을 살펴보도록하죠.

​          1

2                   3

이렇게 노드가 3 개인 그래프를 상상해봅시다.

1에서 3으로 가려면 직접 가는 방법과 2를 경유해가는 방법 이렇게 두 가지로 나눌 수 있을 겁니다. 이 중 뭐가 더 짧은지를 판단해야 합니다.

그렇다면 노드가 n개 정도.. 많이 있다고 생각해봅시다. 이럴 경우 고려해야하는 범위는 순식간에 확장됩니다. i에서 j로 이동하려면 노드 1을 거쳐가는 방법... 노드 2를 거쳐가는 방법... 노드 n-2를 거쳐가는 방법 등등 으로 나뉘며 심지어 노드 1을 거쳐간다 했을 때 i에서 노드 1까지의 최소 거리를 구하는 알고리즘을 다시 적용해야 합니다.

예를 들어 D<sup>1</sup><sub>ij</sub>는 노드 1을 경유하여 i에서 j로 가는 최소 거리라고 가정합시다.

그 다음으로 노드 D<sup>2</sup><sub>ij</sub>는 노드 2를 경유하여 i에서 j로 가는 최소 거리라고 또 가정합니다. 그런데, 여기에서 D<sup>2</sup><sub>ij</sub>는 D<sup>1</sup><sub>i2</sub> + D<sup>1</sup><sub>2j</sub>입니다. 자, 그럼 다음 순서로 가볼까요?

D<sup>3</sup><sub>ij</sub>은 D<sup>2</sup><sub>i3</sub> + D<sup>2</sup><sub>3j</sub>일 겁니다. 그리고 D<sup>2</sup><sub>i3</sub>은 D<sup>1</sup><sub>i2</sub> + D<sup>1</sup><sub>23</sub>이고, D<sup>2</sup><sub>3j</sub>은 D<sup>1</sup><sub>32</sub> + D<sup>1</sup><sub>2j</sub>일 겁니다. 보이시죠?

이 과정을 반복하면 D<sup>k</sup><sub>ij</sub>는 D<sup>k-1</sup><sub>ik</sub> + D<sup>k-1</sup><sub>kj</sub>가 될겁니다. 아, 각각의 단계에선 당연히 i ≠ k, j ≠ k입니다.

이런 방식으로 k가 1에서 n이 될때까지 D<sup>k</sup><sub>ij</sub>를 계산해서 D<sup>n</sup><sub>ij</sub>, 즉 모든 점을 경유 가능한 점들로 고려된 모든 쌍 i와 j의 최단 경로의 거리를 찾는 방식이 플로이드의 모든 쌍 최단 경로 알고리즘입니다.

보면 새로운 D[i, j]를 계산하기 위해서 미리 D[i,k]와 D[k, j]가 계산되어 있어야 합니다. 부분문제의 분할과 반복. 동적 프로그래밍의 특징이죠.

``` 
0  4  2  5  ∞
∞  0  1  ∞  4
1  3  0  1  2
-2 ∞  ∞  0  2
∞ -3  3  1  0
```

다음과 같이 노드들과 거리가 나타나있다고 가정합시다.

k를 거쳐가는 i와 j의 최소값을 쭉 갱신하면 위의 그래프를 갱신할 수 있을 겁니다.

우선 k=1일 때,

D[4, 2] = min(D[4,2], D[4,1]+D[1,4]) = min(∞, -2+4) = 2 로 갱신되고

D[4, 3] = min(D[4,3], D[4,1]+D[1,3]) = min(∞, -2+2) = 0 로 갱신되고

k=2일 때,

D[1, 5] = min(D[1,5], D[1,2]+D[2,5]) = min(∞, 4+4) = 8 로 갱신되고

D[5, 3] = min(D[5,3], D[5,2]+D[2,3]) = min(3, -3+1) = -2 로 갱신되고

k=3일 때 D[2,4] D[2,5] D[3,2] D[3,4] D[3,5] D[5,2] D[5,4] 총 7개의 원소가 갱신됩니다.

k=4일 때 D[3,2] D[4,2] D[5,2] 총 3개의 원소가 갱신되고

k=5일 때 D[2,3] D[3,3] D[4,3] 총  3개의 원소가 갱신됩니다.

최종 결과는

```
0   1   2   3   4
0   0   1   2   3
-1 -1   0   1   2
-2 -1   0   0   2
-3 -3  -2  -1   0
```

다음과 같이 됩니다.

각 k에 대해서 모든 i,j쌍에 대해 계산되므로 총 n×n×n=n<sup>3</sup>회 계산이 이루어지고, 각 계산은 O(1) 시간이 걸립니다.

### 4. 연속 행렬 곱셈

행렬의 곱셈을 수행할 때 원소의 곱셈의 회수를 최소화시켜주는 알고리즘입니다.

이게 무슨 말이냐하면,

10×10 A 행렬과 20×5 B 행렬 그리고 5×15 C 행렬이 있다고 가정해봅시다.

A×B×C를 수행할 때, A와 B를 곱하고 C를 나중에 곱하냐, B와 C를 곱하고 A를 나중에 곱하냐에 따라 결과는 동일하더라도 원소의 곱셈 회수는 큰 차이가 납니다.

A×B는 10×20×5 = 1000번의 곱셈이 필요하고 그 결과인 10×5에 C를 곱하면 또 10×5×15 = 750번의 곱셈이 필요하게 됩니다.

그러나 B×C를 계산하는데는 20×5×15=1500번의 곱셈이 필요하고 그 결과인 20×15에 A를 곱하면 10×20×15=3000번의 곱셈이 추가로 필요해집니다.

즉, 순서만 달리했을 뿐인데 1700번과 4500번, 즉 2800번이나 되는 연산 횟수가 차이나게 되는 것입니다.

그러니 이 문제를 동적 프로그래밍으로 풀이하려면,

우선 A×B×C×D×E를 계산할 때 부분문제들을 구해야 합니다.

{A×B} {B×C} {C×D} {D×E}

{A×B×C} {B×C×D} {C×D×E}

{A×B×C×D} {B×C×D×E}

{A×B×C×D×E}

이런식으로요... 부분문제들은 아까 설명했던 동적 프로그래밍의 성질처럼 상위의 해를 구하는데 중복되어 필요해집니다.{A×B×C} {B×C×D}를 구하는데 동시에 {B×C}가 필요한 것처럼요.

이는 매우 기본적인 DP 알고리즘입니다. 하위의 해를 구하고 그 해를 이용하여 상위의 해를 구해가면 전체문제에 대한 최적의 해를 구할 수 있을 것입니다.

#### 가방 